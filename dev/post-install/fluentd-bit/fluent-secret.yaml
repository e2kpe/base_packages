apiVersion: v1
data:
  filters.conf: |
    [FILTER]
      Name                modify
      Match               *
      Rename message log
    [FILTER]
      Name record_modifier
      Match *
      Record cluster ${cluster}
    [FILTER]
      Name record_modifier
      Match kube.*
      Record fluentbit-tag ${cluster}-container-log
    [FILTER]
      Name record_modifier
      Match other-var-log.*
      Record fluentbit-tag ${cluster}-var-log
    [FILTER]
      Name record_modifier
      Match other-kubelet-service.*
      Record fluentbit-tag ${cluster}-kubelet-service
    [FILTER]
      Name                kubernetes
      Match               kube.*
      Kube_URL            https://kubernetes.default.svc:443
      Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
      Kube_Tag_Prefix     kube.var.log.containers.
      Merge_Log           Off
      Merge_Log_Key       log_processed
      K8S-Logging.Parser  Off
      K8S-Logging.Exclude On
    [FILTER]
      Name                kubernetes
      Match               falco.*
      Kube_URL            https://kubernetes.default.svc:443
      Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
      Kube_Tag_Prefix     kube.var.log.containers.
      Merge_Log           Off
      Merge_Log_Key       log_processed
      K8S-Logging.Parser  Off
      K8S-Logging.Exclude On
  fluent-bit.conf: "@SET cluster=test-tkc\n[Service]\n  Flush         2\n
    \ Log_Level     warning\n  Daemon        off\n  Parsers_File  parsers.conf\n  HTTP_Server
    \  On\n  HTTP_Listen   0.0.0.0\n  HTTP_Port     2020\n  storage.path  /var/log/fluent-bit-storage/\n
    \ storage.sync  normal\n  storage.metrics on\n  storage.checksum  off\n  storage.backlog.mem_limit
    50M\n\n\n  Parsers_File  parsers.conf\n  \n  \n\n@INCLUDE inputs.conf\n@INCLUDE
    filters.conf\n@INCLUDE outputs.conf\n"
  inputs.conf: |
    [INPUT]
      Name tail
      Path /var/log/containers/*.log
      Exclude_Path /var/log/containers/falco*.log
      Parser cri
      Tag kube.*
      Mem_Buf_Limit 5MB
      Skip_Long_Lines On
      storage.type  filesystem
      DB    /var/log/fluent-bit-storage/kube.db
      DB.locking   true
      storage.pause_on_chunks_overlimit true
    [INPUT]
      Name tail
      Path /var/log/containers/falco*.log
      Parser cri
      Tag falco.*
      Mem_Buf_Limit 5MB
      Skip_Long_Lines On
      storage.type  filesystem
      DB    /var/log/fluent-bit-storage/falco.db
      DB.locking   true
      storage.pause_on_chunks_overlimit true
    [INPUT]
      Name tail
      Path /var/log/*.log
      Tag other-var-log.*
      Mem_Buf_Limit 5MB
      Skip_Long_Lines On
      storage.type  filesystem
      DB    /var/log/fluent-bit-storage/others.db
      DB.locking   true
      storage.pause_on_chunks_overlimit true
    [INPUT]
      Name systemd
      Tag other-kubelet-service.*
      Systemd_Filter _SYSTEMD_UNIT=kubelet.service
      Read_From_Tail On
      storage.type  filesystem
      DB    /var/log/fluent-bit-storage/host.db
      DB.locking   true
      storage.pause_on_chunks_overlimit true
  outputs.conf: |
    [OUTPUT]
      Name        kafka
      Match       kube.*
      Brokers     flume1.dev.e2open.com:9092,flume2.dev.e2open.com:9092,flume3.dev.e2open.com:9092
      Topics      ${cluster}
      rdkafka.enable.ssl.certificate.verification false
      rdkafka.security.protocol ssl
      rdkafka.request.required.acks 1
      rdkafka.log.connection.close false
      timestamp_Format iso8601
      storage.total_limit_size 5G
      queue_full_retries 0
    [OUTPUT]
      Name        kafka
      Match       other-*.*
      Brokers     flume1.dev.e2open.com:9092,flume2.dev.e2open.com:9092,flume3.dev.e2open.com:9092
      Topics      ${cluster}
      rdkafka.enable.ssl.certificate.verification false
      rdkafka.security.protocol ssl
      rdkafka.request.required.acks 1
      rdkafka.log.connection.close false
      timestamp_Format iso8601
      storage.total_limit_size 5G
      queue_full_retries 0
    [OUTPUT]
      Name        kafka
      Match       falco.*
      Brokers     flume1.dev.e2open.com:9092,flume2.dev.e2open.com:9092,flume3.dev.e2open.com:9092
      Topics      falco-logs
      rdkafka.enable.ssl.certificate.verification false
      rdkafka.security.protocol ssl
      rdkafka.request.required.acks 1
      rdkafka.log.connection.close false
      timestamp_Format iso8601
      storage.total_limit_size 5G
      queue_full_retries 0
  parsers.conf: |
    [PARSER]
      Name   json
      Format json
      Time_Key time
      Time_Format %d/%b/%Y:%H:%M:%S %z
    [PARSER]

      Name cri
      Format regex
      Regex ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<message>.*)$
      Time_Key    time
      Time_Format %Y-%m-%dT%H:%M:%S.%L%z
  plugins.conf: ""
  streams.conf: ""
kind: ConfigMap
metadata:
  annotations:
  labels:
  name: fluent-bit-config
  namespace: monitor-logging

